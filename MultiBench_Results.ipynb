{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFOvkpfHaPKj",
        "outputId": "b6f8c9c0-a27b-407a-b1f3-a45d22916187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MultiBench' already exists and is not an empty directory.\n",
            "/content/MultiBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PrwFFUEaT7Q",
        "outputId": "5c7cadc7-1750-4c2c-fc1a-b86c63d54950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n",
            "From (redirected): https://drive.google.com/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU&confirm=t&uuid=6ecc32a0-654f-4127-8e71-f945893b91df\n",
            "To: /content/MultiBench/mosi_raw.pkl\n",
            "100% 357M/357M [00:10<00:00, 34.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx_xERf2bE-T",
        "outputId": "4dd79c9d-7a22-4c7b-fc94-2df606fd9e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH5hcDsDaNut",
        "outputId": "7b6f6df0-eff6-40b8-8f8f-3df655aec508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.6112804878048781, 0.6020408163265306\n",
            "Inference Time: 3.120678186416626\n",
            "Inference Params: 1680897\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.Supervised_Learning import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "\n",
        "# # mosi_data.pkl, mosei_senti_data.pkl\n",
        "# # mosi_raw.pkl, mosei_senti_data.pkl, sarcasm.pkl, humor.pkl\n",
        "# # raw_path: mosi.hdf5, mosei.hdf5, sarcasm_raw_text.pkl, humor_raw_text.pkl\n",
        "# # traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "# # mosi/mosei\n",
        "# encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]\n",
        "# head = Sequential(GRU(409, 512, dropout=True, has_padding=False,\n",
        "#                   batch_first=True, last_only=True), MLP(512, 512, 1))\n",
        "\n",
        "\n",
        "# # humor/sarcasm\n",
        "# # encoders = [Identity().cuda(),Identity().cuda(),Identity().cuda()]\n",
        "# # head = Sequential(GRU(752, 1128, dropout=True, has_padding=False, batch_first=True, last_only=True), MLP(1128, 512, 1)).cuda()\n",
        "\n",
        "# fusion = ConcatEarly().cuda()\n",
        "\n",
        "# train(encoders, fusion, head, traindata, validdata, 100, task=\"regression\", optimtype=torch.optim.AdamW,\n",
        "#       is_packed=False, lr=1e-3, save='mosi_ef_r0.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "# print(\"Testing:\")\n",
        "# model = torch.load('/content/mosi_ef_r0.pt').cuda()\n",
        "model = torch.load('/content/mosi_ef_r0.pt')\n",
        "test(model, testdata, 'affect', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task=\"posneg-classification\", no_robust=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(traindata)"
      ],
      "metadata": {
        "id": "gH2KxfHicQwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Ja7D3KhEchxb",
        "outputId": "0eaad909-963f-4391-e951-ebf3a8d2933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
              "the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 123);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "s3dTtJxkbPEC",
        "outputId": "38742938-0e28-42ee-b29b-04838cd7285a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.affect.get_data.Affectdataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.affect.get_data.Affectdataset</b><br/>def __init__(data: Dict, flatten_time_series: bool, aligned: bool=True, task: str=None, max_pad=False, max_pad_num=50, data_type=&#x27;mosi&#x27;, z_norm=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/MultiBench/datasets/affect/get_data.py</a>Implements Affect data as a torch dataset.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 157);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata.dataset.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h-XcwuFS36Z",
        "outputId": "9aecd7f2-47e5-4c9b-afde-4a7d3a0bfbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpEe92bTTAXL",
        "outputId": "945963f0-b9eb-48f6-ecf9-0d16ce0e8a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vision', 'audio', 'text', 'labels', 'id'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['vision'].shape, traindata.dataset.dataset['audio'].shape, traindata.dataset.dataset['text'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cMNJvLcTKCx",
        "outputId": "2b3b420b-c44d-4d17-a210-2f85853becda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1283, 50, 35), (1283, 50, 74), (1283, 50, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.unimodal import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# mosi_data.pkl, mosei_senti_data.pkl\n",
        "# mosi_raw.pkl, mosei_raw.pkl, sarcasm.pkl, humor.pkl\n",
        "# traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "modality_num = 2\n",
        "\n",
        "# mosi/mosei\n",
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True)\n",
        "head = MLP(600, 512, 1)\n",
        "\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder_modality2.pt', save_head='head_modality2.pt', modalnum=modality_num)\n",
        "\n"
      ],
      "metadata": {
        "id": "mFgMy1hNWQ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing when modality set to :2\")\n",
        "encoder = torch.load('encoder.pt')\n",
        "head = torch.load('head.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=modality_num, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbKzAS-eYT_D",
        "outputId": "52c94d1f-8e9c-4825-b5e7-b3c5468bcdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:\n",
            "loss: tensor(1.4386)\n",
            "acc: 0.4329268292682927, 0.4139941690962099\n",
            "Inference Time: 2.0616798400878906\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "# sys.path.append(os.getcwd())\n",
        "# sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
      ],
      "metadata": {
        "id": "gbZwqi6RlMIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOBkdovUlI8O",
        "outputId": "5abce179-bd57-42e0-ddb0-6ddfd4fe07a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.unimodal import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# mosi_data.pkl, mosei_senti_data.pkl\n",
        "# mosi_raw.pkl, mosei_raw.pkl, sarcasm.pkl, humor.pkl\n",
        "# traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "modality_num = 2\n",
        "\n",
        "# mosi/mosei\n",
        "\n",
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder.pt', save_head='head.pt', modalnum=modality_num)\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder.pt').cuda()\n",
        "head = torch.load('head.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=modality_num, no_robust=True)"
      ],
      "metadata": {
        "id": "3as_cV3zi35T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f9f74c-e5d7-4ca6-bd1c-371e75ad94ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.3827, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3888, device='cuda:0')\n",
            "Epoch 2 train loss: tensor(1.3195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3815, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(1.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3866, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 5 train loss: tensor(1.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3844, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.3855, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.3864, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3904, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3987, device='cuda:0')\n",
            "Epoch 10 train loss: tensor(1.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.3718, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 11 train loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3709, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 12 train loss: tensor(1.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3864, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3720, device='cuda:0')\n",
            "Epoch 14 train loss: tensor(1.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3481, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 15 train loss: tensor(1.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.2758, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 16 train loss: tensor(1.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.1519, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 17 train loss: tensor(0.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.1506, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 18 train loss: tensor(0.8699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.0353, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 19 train loss: tensor(0.7410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(0.9866, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 20 train loss: tensor(0.6337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.0632, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(0.5588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(0.9913, device='cuda:0')\n",
            "Epoch 22 train loss: tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(0.9625, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 23 train loss: tensor(0.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(0.9755, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(0.9713, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(0.9631, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(0.9677, device='cuda:0')\n",
            "Epoch 28 train loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(0.9739, device='cuda:0')\n",
            "Epoch 29 train loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(0.9873, device='cuda:0')\n",
            "Epoch 30 train loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(0.9852, device='cuda:0')\n",
            "Epoch 31 train loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(0.9913, device='cuda:0')\n",
            "Epoch 32 train loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(0.9792, device='cuda:0')\n",
            "Epoch 33 train loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(0.9817, device='cuda:0')\n",
            "Epoch 34 train loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(0.9847, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(0.9952, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(0.9690, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.0064, device='cuda:0')\n",
            "Epoch 38 train loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(0.9711, device='cuda:0')\n",
            "Epoch 39 train loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(0.9834, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(0.9941, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(0.9782, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(0.9856, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.0084, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.0058, device='cuda:0')\n",
            "Epoch 45 train loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.0013, device='cuda:0')\n",
            "Epoch 46 train loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.0128, device='cuda:0')\n",
            "Epoch 47 train loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.0232, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.0155, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(0.9797, device='cuda:0')\n",
            "Epoch 50 train loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.0142, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(0.9839, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.0007, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.0043, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.0028, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(0.9846, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(0.9932, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(0.9866, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(0.9990, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(0.9935, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.0195, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.0095, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(0.9790, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(0.9867, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.0241, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(0.9950, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.0212, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(0.9891, device='cuda:0')\n",
            "Epoch 70 train loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(0.9983, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.0055, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.0181, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.0050, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(0.9997, device='cuda:0')\n",
            "Epoch 75 train loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(0.9981, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(0.9973, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(0.9891, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.0062, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(0.9851, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.0078, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.0167, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(1.0198, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(0.9977, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.0077, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(1.0295, device='cuda:0')\n",
            "Epoch 87 train loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.0151, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.0117, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(0.9955, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.0119, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(1.0037, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.0022, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(1.0087, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.0204, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(0.9948, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.0033, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.0182, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(1.0206, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Epoch 101 train loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(1.0094, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(0.9940, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(0.9792, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(1.0040, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(1.0072, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(1.0003, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(1.0090, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(0.9952, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.0032, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(1.0083, device='cuda:0')\n",
            "Epoch 113 train loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.0168, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(1.0319, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.0387, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(1.0047, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(1.0119, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.0111, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(1.0027, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.0110, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.0081, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(1.0232, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(0.9933, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(0.9881, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(0.9950, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.0109, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(1.0018, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(1.0072, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(1.0352, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(0.9937, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(0.9839, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(1.0054, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(0.9991, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(1.0132, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(0.9940, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(1.0073, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(1.0078, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(1.0126, device='cuda:0')\n",
            "Epoch 140 train loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(0.9969, device='cuda:0')\n",
            "Epoch 142 train loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(0.9988, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(1.0057, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(0.9995, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(1.0131, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(1.0126, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(1.0240, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(1.0253, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(1.0170, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(1.0165, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(1.0162, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(1.0000, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(1.0124, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(1.0089, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(1.0097, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(1.0291, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(0.9987, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(1.0318, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.0195, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(1.0454, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(1.0231, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(1.0452, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(1.0384, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(1.0321, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.0888, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(1.0655, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(1.0166, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(1.0690, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(1.0348, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(1.0432, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(1.0662, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(1.0722, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(1.0625, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(1.0573, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(1.0612, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(1.0565, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(1.0665, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(1.0607, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(1.0526, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(1.0651, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(1.0563, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(1.0651, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(1.0417, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(1.0447, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(1.0511, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(1.0486, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(1.0649, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.0595, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.0539, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(1.0684, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.0675, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(1.0597, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(1.0576, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(1.0640, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.0390, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(1.0574, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.0670, device='cuda:0')\n",
            "Training Time: 198.96296048164368\n",
            "Training Peak Mem: 1466.515625\n",
            "Training Params: 1931825\n",
            "Testing:\n",
            "loss: tensor(1.0727, device='cuda:0')\n",
            "acc: 0.7332317073170732, 0.7274052478134111\n",
            "Inference Time: 0.6458330154418945\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhK5iY5vlbXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TvULxoB2u4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "1. Only vision\n",
        "2. Only audio\n",
        "3. Only text\n",
        "4. All three modalities"
      ],
      "metadata": {
        "id": "IK6d1pXlu5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(35, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder0.pt', save_head='head0.pt', modalnum= 0)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder0.pt').cuda()\n",
        "head = torch.load('head0.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=0, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi4mQzhrlemr",
        "outputId": "ff59cb37-8695-4fb3-bf13-2e2b10ec8deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:\n",
            "loss: tensor(1.6484, device='cuda:0')\n",
            "acc: 0.5350609756097561, 0.5291545189504373\n",
            "Inference Time: 0.41711854934692383\n",
            "Inference Params: 1454825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(74, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder1.pt', save_head='head1.pt', modalnum= 1)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder1.pt').cuda()\n",
        "head = torch.load('head1.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=1, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO_VCtLcnjvw",
        "outputId": "706a872e-caef-4e1b-cd0c-806ce9cd1c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.3793, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 2 train loss: tensor(1.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3863, device='cuda:0')\n",
            "Epoch 3 train loss: tensor(1.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3865, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3818, device='cuda:0')\n",
            "Epoch 5 train loss: tensor(1.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3865, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.4417, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.4052, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3966, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3740, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 10 train loss: tensor(1.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.3874, device='cuda:0')\n",
            "Epoch 11 train loss: tensor(1.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3916, device='cuda:0')\n",
            "Epoch 12 train loss: tensor(1.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3701, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 14 train loss: tensor(1.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3875, device='cuda:0')\n",
            "Epoch 15 train loss: tensor(1.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.3755, device='cuda:0')\n",
            "Epoch 16 train loss: tensor(1.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.3890, device='cuda:0')\n",
            "Epoch 17 train loss: tensor(1.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.3841, device='cuda:0')\n",
            "Epoch 18 train loss: tensor(1.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.3828, device='cuda:0')\n",
            "Epoch 19 train loss: tensor(1.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(1.4542, device='cuda:0')\n",
            "Epoch 20 train loss: tensor(1.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.3877, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(1.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(1.4081, device='cuda:0')\n",
            "Epoch 22 train loss: tensor(1.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(1.4202, device='cuda:0')\n",
            "Epoch 23 train loss: tensor(1.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(1.4072, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(1.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(1.3822, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(1.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(1.4010, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(1.3829, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(1.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(1.4068, device='cuda:0')\n",
            "Epoch 28 train loss: tensor(1.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(1.4199, device='cuda:0')\n",
            "Epoch 29 train loss: tensor(1.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(1.3871, device='cuda:0')\n",
            "Epoch 30 train loss: tensor(1.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(1.4357, device='cuda:0')\n",
            "Epoch 31 train loss: tensor(1.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(1.3921, device='cuda:0')\n",
            "Epoch 32 train loss: tensor(1.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(1.3992, device='cuda:0')\n",
            "Epoch 33 train loss: tensor(1.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(1.4165, device='cuda:0')\n",
            "Epoch 34 train loss: tensor(1.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(1.4696, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(1.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(1.3956, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(1.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(1.3953, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(1.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.4864, device='cuda:0')\n",
            "Epoch 38 train loss: tensor(1.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(1.4462, device='cuda:0')\n",
            "Epoch 39 train loss: tensor(1.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(1.4316, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(1.4138, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(1.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(1.4161, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(1.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(1.4241, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(1.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.4946, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(1.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.4028, device='cuda:0')\n",
            "Epoch 45 train loss: tensor(1.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.4523, device='cuda:0')\n",
            "Epoch 46 train loss: tensor(1.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.4264, device='cuda:0')\n",
            "Epoch 47 train loss: tensor(1.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.4578, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(1.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.4466, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(1.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(1.4777, device='cuda:0')\n",
            "Epoch 50 train loss: tensor(1.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.4631, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(1.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(1.4112, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(1.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.4600, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(1.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.4647, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(1.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.4440, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(1.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.4280, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(1.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.4123, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(1.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(1.4311, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(1.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(1.4155, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(1.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(1.4959, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(1.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(1.4936, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(1.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(1.4530, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(1.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.4957, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(1.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.4572, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(1.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(1.4141, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(1.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(1.4404, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(1.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.5518, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(1.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(1.4802, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(1.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.4660, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(1.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(1.5076, device='cuda:0')\n",
            "Epoch 70 train loss: tensor(1.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(1.5109, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(1.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.4966, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(1.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.5050, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(1.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.4588, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(1.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(1.5056, device='cuda:0')\n",
            "Epoch 75 train loss: tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(1.5251, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(1.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(1.5353, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(1.5405, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.5587, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(1.5285, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.5748, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.5624, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(1.6180, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(1.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(1.5009, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.5404, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(1.5252, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(1.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(1.5440, device='cuda:0')\n",
            "Epoch 87 train loss: tensor(1.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(1.5501, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(1.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.5442, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.6032, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(1.5266, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.5241, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(1.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(1.5448, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(1.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.5515, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(1.5919, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(1.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.5279, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(1.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(1.6133, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.5228, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.5261, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(1.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(1.6016, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(1.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(1.5739, device='cuda:0')\n",
            "Epoch 101 train loss: tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(1.5723, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(1.5575, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(1.0428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(1.6263, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(1.0367, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(1.6353, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(1.5459, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(1.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(1.5716, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(1.0490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(1.5553, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(1.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(1.5945, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(1.5371, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(1.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.5925, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(1.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.6071, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(1.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(1.5567, device='cuda:0')\n",
            "Epoch 113 train loss: tensor(1.0294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.6090, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(1.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(1.5997, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(1.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.6099, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(1.6183, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(1.5977, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.5929, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(1.0320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(1.5718, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.5837, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.5508, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(1.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(1.5514, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(1.0131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(1.5860, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(1.5690, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(1.6308, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.4633, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(1.0389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(1.6391, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(1.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(1.6446, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(1.5861, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(1.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(1.5221, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(1.6022, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(1.5981, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(1.0293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(1.5812, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(1.5986, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(1.6381, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(1.6076, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.9918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(1.5631, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.9836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(1.5816, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(1.6064, device='cuda:0')\n",
            "Epoch 140 train loss: tensor(0.9728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(1.6147, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.9812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(1.6596, device='cuda:0')\n",
            "Epoch 142 train loss: tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(1.6289, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(1.6580, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.9851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(1.6524, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.9553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(1.6299, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(1.6012, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.9469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(1.5835, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(1.5843, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.9392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(1.6880, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.9458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(1.5223, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.9350, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(1.5344, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.9299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(1.6588, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.9402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(1.5589, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.9246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(1.5852, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.9212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(1.6677, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(1.5706, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(1.0137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(1.6761, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.9288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(1.7220, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.9497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(1.5944, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.8994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(1.7024, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.9156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.5983, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(1.6772, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.9188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(1.6285, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.8781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(1.5928, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.8898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(1.6825, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.9696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(1.6197, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.6105, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(1.6543, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(1.6114, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.8796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(1.6096, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.8670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(1.6848, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.8913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(1.6211, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(1.5565, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.8775, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(1.6689, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.8746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(1.7173, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(1.6582, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.8740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(1.6280, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(1.6177, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.8402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(1.7046, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(1.6469, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.8316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(1.6027, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.8499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(1.6648, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(1.5946, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.8579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(1.6656, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.8661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(1.5291, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(1.6576, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(1.5510, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(1.6814, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(1.6296, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.6818, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.6221, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(1.5730, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.6207, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.8291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(1.6406, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(1.6451, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(1.6518, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.8368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.6498, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.8178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(1.6435, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.8200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.6985, device='cuda:0')\n",
            "Training Time: 197.91238403320312\n",
            "Training Peak Mem: 1478.1484375\n",
            "Training Params: 1525025\n",
            "Testing:\n",
            "loss: tensor(1.4827, device='cuda:0')\n",
            "acc: 0.4405487804878049, 0.42128279883381925\n",
            "Inference Time: 0.4024844169616699\n",
            "Inference Params: 1525025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder2.pt', save_head='head2.pt', modalnum= 2)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder2.pt').cuda()\n",
        "head = torch.load('head2.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=2, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0eTG-uZnwOC",
        "outputId": "2c72094b-ead4-4ba9-cc2c-13ddf8fa7b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.5246, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.5094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3872, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(1.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3727, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(1.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3896, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3694, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 5 train loss: tensor(1.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3795, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.3787, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.3914, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3696, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3980, device='cuda:0')\n",
            "Epoch 10 train loss: tensor(1.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.4308, device='cuda:0')\n",
            "Epoch 11 train loss: tensor(1.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3818, device='cuda:0')\n",
            "Epoch 12 train loss: tensor(1.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3836, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3779, device='cuda:0')\n",
            "Epoch 14 train loss: tensor(1.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3703, device='cuda:0')\n",
            "Epoch 15 train loss: tensor(1.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.3738, device='cuda:0')\n",
            "Epoch 16 train loss: tensor(1.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.3774, device='cuda:0')\n",
            "Epoch 17 train loss: tensor(1.3175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.3755, device='cuda:0')\n",
            "Epoch 18 train loss: tensor(1.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.3692, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 19 train loss: tensor(1.3085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(1.3926, device='cuda:0')\n",
            "Epoch 20 train loss: tensor(1.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.3713, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(1.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(1.3656, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 22 train loss: tensor(1.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(1.3931, device='cuda:0')\n",
            "Epoch 23 train loss: tensor(1.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(1.3874, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(1.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(1.3742, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(1.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(1.3798, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(1.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(1.3674, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(1.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(1.3184, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 28 train loss: tensor(1.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(1.2869, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 29 train loss: tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(1.2373, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 30 train loss: tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(1.1970, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 31 train loss: tensor(1.0321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(1.1535, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 32 train loss: tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(1.1448, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 33 train loss: tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(1.1110, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 34 train loss: tensor(0.8788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(1.1379, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(1.1848, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(0.8166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(1.1192, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.0662, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 38 train loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(1.0303, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 39 train loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(1.0403, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(0.6406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(1.0576, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(1.0455, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(1.0337, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.0652, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.0279, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 45 train loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.0233, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 46 train loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.0086, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 47 train loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.0745, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.0465, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(1.0022, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 50 train loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.0405, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(1.0306, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.0131, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.0247, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.0175, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.0256, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(1.0326, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(1.0157, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(1.0228, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(1.0216, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(1.0366, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.0282, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.0436, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(1.0323, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(1.0261, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.0568, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(0.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(1.0253, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.0345, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(0.9976, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 70 train loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(1.0287, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.0052, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.0060, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.0275, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 75 train loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(1.0261, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(1.0142, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(1.0082, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.0257, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(1.0073, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.0263, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.0021, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(0.9974, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(1.0280, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.0019, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(1.0387, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(0.9875, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 87 train loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(1.0146, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.0178, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.0002, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(0.9903, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.0343, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(0.9962, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.0282, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.0015, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(1.0040, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.0001, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.0315, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(0.9968, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(0.9801, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 101 train loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(0.9996, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(1.0176, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(1.0143, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(1.0002, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(0.9959, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(0.9863, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(0.9961, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(0.9987, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.0149, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.0042, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(0.9776, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 113 train loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.0011, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(0.9902, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.0074, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(0.9882, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(0.9967, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.0058, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(0.9904, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.0168, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(0.9943, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(0.9810, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(1.0130, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(1.0015, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.0053, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(0.9945, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(0.9882, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(0.9825, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(1.0053, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(0.9878, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(1.0081, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(0.9883, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(1.0100, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(0.9901, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(0.9850, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(0.9956, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(0.9764, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 140 train loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(0.9824, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(0.9659, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 142 train loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(1.0114, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(0.9947, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(0.9917, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(0.9852, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(0.9854, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(0.9968, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(0.9973, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(0.9791, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(0.9886, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(0.9797, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(0.9847, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(0.9989, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(0.9957, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(0.9698, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(0.9745, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(0.9855, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(0.9878, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(0.9834, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(0.9860, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(0.9965, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(0.9799, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(0.9873, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.0112, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(0.9821, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(0.9991, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(0.9877, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(0.9887, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(0.9801, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(0.9919, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(0.9918, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(0.9962, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(0.9914, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(0.9941, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(0.9836, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(0.9908, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(0.9881, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(0.9993, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(0.9890, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(0.9865, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(0.9924, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(0.9877, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(0.9969, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(0.9904, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.0035, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.0218, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.0135, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(0.9889, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(0.9965, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(0.9955, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.0181, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(0.9912, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.0017, device='cuda:0')\n",
            "Training Time: 204.93540453910828\n",
            "Training Peak Mem: 1483.83203125\n",
            "Training Params: 1931825\n",
            "Testing:\n",
            "loss: tensor(1.0228, device='cuda:0')\n",
            "acc: 0.7484756097560976, 0.739067055393586\n",
            "Inference Time: 0.4056661128997803\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from training_structures.Supervised_Learning import train, test # noqa\n",
        "from fusions.mult import MULTModel # noqa\n",
        "from unimodals.common_models import Identity, MLP # noqa\n",
        "from datasets.affect.get_data import get_dataloader # noqa\n",
        "from fusions.common_fusions import Concat # noqa\n",
        "traindata, validdata, test_robust = get_dataloader('/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True)\n",
        "\n",
        "\n",
        "class HParams():\n",
        "        num_heads = 8\n",
        "        layers = 4\n",
        "        attn_dropout = 0.1\n",
        "        attn_dropout_modalities = [0,0,0.1]\n",
        "        relu_dropout = 0.1\n",
        "        res_dropout = 0.1\n",
        "        out_dropout = 0.1\n",
        "        embed_dropout = 0.2\n",
        "        embed_dim = 40\n",
        "        attn_mask = True\n",
        "        output_dim = 1\n",
        "        all_steps = False\n",
        "\n",
        "encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]\n",
        "# encoders = [GRU(35, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda(),\n",
        "#             GRU(74, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda(),\n",
        "#             GRU(300, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda()]\n",
        "fusion = MULTModel(3, [35, 74, 300], hyp_params=HParams).cuda()\n",
        "# fusion = MULTModel(3, [371, 81, 300], hyp_params=HParams).cuda()\n",
        "head = Identity().cuda()\n",
        "# head = MLP(600, 512, 1).cuda()\n",
        "train(encoders, fusion, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, early_stop=False, is_packed=False, lr=1e-3, clip_val=1.0, save='mosi_mult_best.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "print(\"Testing:\")\n",
        "model = torch.load('mosi_mult_best.pt').cuda()\n",
        "\n",
        "test(model=model, test_dataloaders_all=test_robust, dataset='mosi', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task='posneg-classification', no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8MlGf5p57k",
        "outputId": "eda92e55-2cd1-4644-942e-3d0a29200f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: 1.3420194387435913\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: 1.1382781267166138\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(0.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: 1.0845630168914795\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(0.9198, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: 1.0826172828674316\n",
            "Saving Best\n",
            "Epoch 4 train loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: 1.1367664337158203\n",
            "Epoch 5 train loss: tensor(0.8507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: 1.029336929321289\n",
            "Saving Best\n",
            "Epoch 6 train loss: tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: 0.9345373511314392\n",
            "Saving Best\n",
            "Epoch 7 train loss: tensor(0.7718, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: 0.9492958784103394\n",
            "Epoch 8 train loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: 1.0193325281143188\n",
            "Epoch 9 train loss: tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: 1.064608097076416\n",
            "Epoch 10 train loss: tensor(0.7088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: 0.9261780381202698\n",
            "Saving Best\n",
            "Epoch 11 train loss: tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: 0.9808047413825989\n",
            "Epoch 12 train loss: tensor(0.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: 0.9107573628425598\n",
            "Saving Best\n",
            "Epoch 13 train loss: tensor(0.6743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: 0.8920506238937378\n",
            "Saving Best\n",
            "Epoch 14 train loss: tensor(0.6382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: 0.9045642614364624\n",
            "Epoch 15 train loss: tensor(0.6178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: 0.9601284861564636\n",
            "Epoch 16 train loss: tensor(0.5881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: 0.8878652453422546\n",
            "Saving Best\n",
            "Epoch 17 train loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: 0.9483947157859802\n",
            "Epoch 18 train loss: tensor(0.5921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: 0.9269450306892395\n",
            "Epoch 19 train loss: tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: 0.9397802352905273\n",
            "Epoch 20 train loss: tensor(0.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: 0.9993156790733337\n",
            "Epoch 21 train loss: tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: 0.9308793544769287\n",
            "Epoch 22 train loss: tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: 0.9257575273513794\n",
            "Epoch 23 train loss: tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: 1.1088979244232178\n",
            "Epoch 24 train loss: tensor(0.5471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: 0.9908510446548462\n",
            "Epoch 25 train loss: tensor(0.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: 0.9304904937744141\n",
            "Epoch 26 train loss: tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: 1.0223578214645386\n",
            "Epoch 27 train loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: 0.9822674989700317\n",
            "Epoch 28 train loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: 0.9778831601142883\n",
            "Epoch 29 train loss: tensor(0.4654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: 1.0065172910690308\n",
            "Epoch 30 train loss: tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: 0.9862286448478699\n",
            "Epoch 31 train loss: tensor(0.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: 1.0055632591247559\n",
            "Epoch 32 train loss: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: 0.9680385589599609\n",
            "Epoch 33 train loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: 0.9825625419616699\n",
            "Epoch 34 train loss: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: 0.9492112398147583\n",
            "Epoch 35 train loss: tensor(0.4377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: 0.9693173170089722\n",
            "Epoch 36 train loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: 0.9280733466148376\n",
            "Epoch 37 train loss: tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: 0.9200366139411926\n",
            "Epoch 38 train loss: tensor(0.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: 1.0344722270965576\n",
            "Epoch 39 train loss: tensor(0.4101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: 0.9752023220062256\n",
            "Epoch 40 train loss: tensor(0.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: 0.9698415994644165\n",
            "Epoch 41 train loss: tensor(0.4070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: 0.9666476845741272\n",
            "Epoch 42 train loss: tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: 1.0020214319229126\n",
            "Epoch 43 train loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: 0.9535757899284363\n",
            "Epoch 44 train loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: 0.9922152757644653\n",
            "Epoch 45 train loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: 0.9755028486251831\n",
            "Epoch 46 train loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: 0.9342990517616272\n",
            "Epoch 47 train loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: 0.9770538210868835\n",
            "Epoch 48 train loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: 0.9589951038360596\n",
            "Epoch 49 train loss: tensor(0.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: 0.950085461139679\n",
            "Epoch 50 train loss: tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: 0.971932590007782\n",
            "Epoch 51 train loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: 0.9540212750434875\n",
            "Epoch 52 train loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: 0.9687593579292297\n",
            "Epoch 53 train loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: 1.0127297639846802\n",
            "Epoch 54 train loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: 1.0176782608032227\n",
            "Epoch 55 train loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: 0.9771816730499268\n",
            "Epoch 56 train loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: 0.9896891117095947\n",
            "Epoch 57 train loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: 1.0221564769744873\n",
            "Epoch 58 train loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: 0.9940126538276672\n",
            "Epoch 59 train loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: 0.9547644853591919\n",
            "Epoch 60 train loss: tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: 1.0236622095108032\n",
            "Epoch 61 train loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: 0.9624140858650208\n",
            "Epoch 62 train loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: 1.023120403289795\n",
            "Epoch 63 train loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: 1.0322599411010742\n",
            "Epoch 64 train loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: 1.002608299255371\n",
            "Epoch 65 train loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: 0.9725083112716675\n",
            "Epoch 66 train loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: 0.9999511241912842\n",
            "Epoch 67 train loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: 0.9871615767478943\n",
            "Epoch 68 train loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: 0.9698127508163452\n",
            "Epoch 69 train loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: 1.0251303911209106\n",
            "Epoch 70 train loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: 0.9945051670074463\n",
            "Epoch 71 train loss: tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: 0.9308512210845947\n",
            "Epoch 72 train loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: 1.029085397720337\n",
            "Epoch 73 train loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: 0.9794439673423767\n",
            "Epoch 74 train loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: 0.9596415162086487\n",
            "Epoch 75 train loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: 0.9721189737319946\n",
            "Epoch 76 train loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: 0.9872156977653503\n",
            "Epoch 77 train loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: 0.9795811176300049\n",
            "Epoch 78 train loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: 0.9903020262718201\n",
            "Epoch 79 train loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: 0.9906467795372009\n",
            "Epoch 80 train loss: tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: 1.0013707876205444\n",
            "Epoch 81 train loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: 0.9622491002082825\n",
            "Epoch 82 train loss: tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: 1.0216041803359985\n",
            "Epoch 83 train loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: 0.9907076954841614\n",
            "Epoch 84 train loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: 1.0035773515701294\n",
            "Epoch 85 train loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: 0.9531477689743042\n",
            "Epoch 86 train loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: 1.030273675918579\n",
            "Epoch 87 train loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: 1.004150629043579\n",
            "Epoch 88 train loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: 0.9987584352493286\n",
            "Epoch 89 train loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: 1.0313159227371216\n",
            "Epoch 90 train loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: 1.0187726020812988\n",
            "Epoch 91 train loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: 1.04469633102417\n",
            "Epoch 92 train loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: 1.037007451057434\n",
            "Epoch 93 train loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: 0.9473686814308167\n",
            "Epoch 94 train loss: tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: 1.0131196975708008\n",
            "Epoch 95 train loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: 0.9740476012229919\n",
            "Epoch 96 train loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: 1.0194593667984009\n",
            "Epoch 97 train loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: 0.9920296669006348\n",
            "Epoch 98 train loss: tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: 1.0343667268753052\n",
            "Epoch 99 train loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: 1.032148838043213\n",
            "Epoch 100 train loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: 1.0084530115127563\n",
            "Epoch 101 train loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: 1.0279017686843872\n",
            "Epoch 102 train loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: 0.9595426321029663\n",
            "Epoch 103 train loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: 1.0478320121765137\n",
            "Epoch 104 train loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: 0.9633126258850098\n",
            "Epoch 105 train loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: 1.0025043487548828\n",
            "Epoch 106 train loss: tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: 1.0175926685333252\n",
            "Epoch 107 train loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: 1.012511134147644\n",
            "Epoch 108 train loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: 1.078550934791565\n",
            "Epoch 109 train loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: 1.021303415298462\n",
            "Epoch 110 train loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: 0.9760705232620239\n",
            "Epoch 111 train loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: 1.033212661743164\n",
            "Epoch 112 train loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: 0.9839805364608765\n",
            "Epoch 113 train loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: 0.976973295211792\n",
            "Epoch 114 train loss: tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: 1.0079988241195679\n",
            "Epoch 115 train loss: tensor(0.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: 0.9890938997268677\n",
            "Epoch 116 train loss: tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: 1.0282354354858398\n",
            "Epoch 117 train loss: tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: 1.0414282083511353\n",
            "Epoch 118 train loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: 1.0453194379806519\n",
            "Epoch 119 train loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: 1.0071548223495483\n",
            "Epoch 120 train loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: 1.0240561962127686\n",
            "Epoch 121 train loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: 1.0289419889450073\n",
            "Epoch 122 train loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: 1.0410385131835938\n",
            "Epoch 123 train loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: 1.0323376655578613\n",
            "Epoch 124 train loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: 1.0083222389221191\n",
            "Epoch 125 train loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: 1.008086085319519\n",
            "Epoch 126 train loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: 1.0031408071517944\n",
            "Epoch 127 train loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: 1.0297589302062988\n",
            "Epoch 128 train loss: tensor(0.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: 1.0704381465911865\n",
            "Epoch 129 train loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: 1.0355547666549683\n",
            "Epoch 130 train loss: tensor(0.2110, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: 1.066978096961975\n",
            "Epoch 131 train loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: 0.997609555721283\n",
            "Epoch 132 train loss: tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: 1.0012637376785278\n",
            "Epoch 133 train loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: 1.0438734292984009\n",
            "Epoch 134 train loss: tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: 1.0068100690841675\n",
            "Epoch 135 train loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: 1.053344964981079\n",
            "Epoch 136 train loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: 1.0483365058898926\n",
            "Epoch 137 train loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: 1.0798346996307373\n",
            "Epoch 138 train loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: 1.0104795694351196\n",
            "Epoch 139 train loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: 1.0238687992095947\n",
            "Epoch 140 train loss: tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: 1.0044142007827759\n",
            "Epoch 141 train loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: 1.0317513942718506\n",
            "Epoch 142 train loss: tensor(0.1975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: 1.0143829584121704\n",
            "Epoch 143 train loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: 1.0483325719833374\n",
            "Epoch 144 train loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: 1.0316511392593384\n",
            "Epoch 145 train loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: 0.9962949156761169\n",
            "Epoch 146 train loss: tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: 1.066615104675293\n",
            "Epoch 147 train loss: tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: 1.0290940999984741\n",
            "Epoch 148 train loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: 1.064458966255188\n",
            "Epoch 149 train loss: tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: 1.0527347326278687\n",
            "Epoch 150 train loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: 0.9869419932365417\n",
            "Epoch 151 train loss: tensor(0.1980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: 1.058513879776001\n",
            "Epoch 152 train loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: 1.023321270942688\n",
            "Epoch 153 train loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: 0.9843906760215759\n",
            "Epoch 154 train loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: 1.014670968055725\n",
            "Epoch 155 train loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: 1.0357359647750854\n",
            "Epoch 156 train loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: 1.033434510231018\n",
            "Epoch 157 train loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: 1.0950539112091064\n",
            "Epoch 158 train loss: tensor(0.2150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: 1.0198677778244019\n",
            "Epoch 159 train loss: tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: 1.0514180660247803\n",
            "Epoch 160 train loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: 1.068223476409912\n",
            "Epoch 161 train loss: tensor(0.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: 1.005568027496338\n",
            "Epoch 162 train loss: tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: 1.0172821283340454\n",
            "Epoch 163 train loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: 1.0596314668655396\n",
            "Epoch 164 train loss: tensor(0.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: 1.044511318206787\n",
            "Epoch 165 train loss: tensor(0.1834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: 1.0517017841339111\n",
            "Epoch 166 train loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: 1.0752562284469604\n",
            "Epoch 167 train loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: 1.0404762029647827\n",
            "Epoch 168 train loss: tensor(0.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: 1.0385323762893677\n",
            "Epoch 169 train loss: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: 1.0824246406555176\n",
            "Epoch 170 train loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: 1.024451732635498\n",
            "Epoch 171 train loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: 1.0826349258422852\n",
            "Epoch 172 train loss: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: 1.0414695739746094\n",
            "Epoch 173 train loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: 1.0501432418823242\n",
            "Epoch 174 train loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: 1.0178240537643433\n",
            "Epoch 175 train loss: tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: 1.0487802028656006\n",
            "Epoch 176 train loss: tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: 1.0540953874588013\n",
            "Epoch 177 train loss: tensor(0.1813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: 1.072153925895691\n",
            "Epoch 178 train loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: 0.9898752570152283\n",
            "Epoch 179 train loss: tensor(0.1777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: 1.0553929805755615\n",
            "Epoch 180 train loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: 1.0240910053253174\n",
            "Epoch 181 train loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: 1.037650227546692\n",
            "Epoch 182 train loss: tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: 0.9533100724220276\n",
            "Epoch 183 train loss: tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: 0.9886252284049988\n",
            "Epoch 184 train loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: 0.9867921471595764\n",
            "Epoch 185 train loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: 0.973131537437439\n",
            "Epoch 186 train loss: tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: 0.9990871548652649\n",
            "Epoch 187 train loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: 1.056857943534851\n",
            "Epoch 188 train loss: tensor(0.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: 1.0089110136032104\n",
            "Epoch 189 train loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: 1.0533241033554077\n",
            "Epoch 190 train loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: 1.0344886779785156\n",
            "Epoch 191 train loss: tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: 0.9785027503967285\n",
            "Epoch 192 train loss: tensor(0.1819, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: 1.0132030248641968\n",
            "Epoch 193 train loss: tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: 1.0254566669464111\n",
            "Epoch 194 train loss: tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: 0.9635250568389893\n",
            "Epoch 195 train loss: tensor(0.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: 0.9877593517303467\n",
            "Epoch 196 train loss: tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: 0.9990677833557129\n",
            "Epoch 197 train loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: 0.9649110436439514\n",
            "Epoch 198 train loss: tensor(0.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: 1.0312869548797607\n",
            "Epoch 199 train loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: 0.9980549216270447\n",
            "Training Time: 1700.0986104011536\n",
            "Training Peak Mem: 2946.37109375\n",
            "Training Params: 3080321\n",
            "Testing:\n",
            "acc: 0.6966463414634146, 0.6924198250728864\n",
            "Inference Time: 1.7913661003112793\n",
            "Inference Params: 3080321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLTxl0nzqF0X",
        "outputId": "383a11c5-0142-4e22-cf70-b17c8bdba5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vision', 'audio', 'text', 'labels', 'id'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['vision'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Ln4ZkvrZbb",
        "outputId": "40e0d668-17af-47ec-9bee-7e12e22864aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['audio'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wv3hgnlrd0T",
        "outputId": "d2987405-bdb4-4183-9435-8006ead90f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['text'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PTy5OxCrg_O",
        "outputId": "47bdd5a4-d207-4d27-9e11-a00ff7f1f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMrbbj9mriHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}