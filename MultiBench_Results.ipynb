{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench\n",
        "!pip install gdown && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n",
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFOvkpfHaPKj",
        "outputId": "8384d347-2906-4adf-c115-d454c28ae205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 6943, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 6943 (delta 72), reused 121 (delta 60), pack-reused 6789\u001b[K\n",
            "Receiving objects: 100% (6943/6943), 51.07 MiB | 20.91 MiB/s, done.\n",
            "Resolving deltas: 100% (4258/4258), done.\n",
            "/content/MultiBench\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n",
            "From (redirected): https://drive.google.com/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU&confirm=t&uuid=13024971-1adc-4598-96d3-2f958c5a4f18\n",
            "To: /content/MultiBench/mosi_raw.pkl\n",
            "100% 357M/357M [00:04<00:00, 76.6MB/s]\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PrwFFUEaT7Q",
        "outputId": "fe776b51-f0a0-44e8-a82f-0060fd73d4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n",
            "From (redirected): https://drive.google.com/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU&confirm=t&uuid=bd959679-f18c-4922-b1b0-6df26ec1e384\n",
            "To: /content/MultiBench/mosi_raw.pkl\n",
            "100% 357M/357M [00:04<00:00, 78.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx_xERf2bE-T",
        "outputId": "d014e80c-f0c4-4890-fcd4-a81a9c445297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH5hcDsDaNut",
        "outputId": "7b6f6df0-eff6-40b8-8f8f-3df655aec508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.6112804878048781, 0.6020408163265306\n",
            "Inference Time: 3.120678186416626\n",
            "Inference Params: 1680897\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.Supervised_Learning import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "\n",
        "# # mosi_data.pkl, mosei_senti_data.pkl\n",
        "# # mosi_raw.pkl, mosei_senti_data.pkl, sarcasm.pkl, humor.pkl\n",
        "# # raw_path: mosi.hdf5, mosei.hdf5, sarcasm_raw_text.pkl, humor_raw_text.pkl\n",
        "# # traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "# # mosi/mosei\n",
        "# encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]\n",
        "# head = Sequential(GRU(409, 512, dropout=True, has_padding=False,\n",
        "#                   batch_first=True, last_only=True), MLP(512, 512, 1))\n",
        "\n",
        "\n",
        "# # humor/sarcasm\n",
        "# # encoders = [Identity().cuda(),Identity().cuda(),Identity().cuda()]\n",
        "# # head = Sequential(GRU(752, 1128, dropout=True, has_padding=False, batch_first=True, last_only=True), MLP(1128, 512, 1)).cuda()\n",
        "\n",
        "# fusion = ConcatEarly().cuda()\n",
        "\n",
        "# train(encoders, fusion, head, traindata, validdata, 100, task=\"regression\", optimtype=torch.optim.AdamW,\n",
        "#       is_packed=False, lr=1e-3, save='mosi_ef_r0.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "# print(\"Testing:\")\n",
        "# model = torch.load('/content/mosi_ef_r0.pt').cuda()\n",
        "model = torch.load('/content/mosi_ef_r0.pt')\n",
        "test(model, testdata, 'affect', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task=\"posneg-classification\", no_robust=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(traindata)"
      ],
      "metadata": {
        "id": "gH2KxfHicQwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Ja7D3KhEchxb",
        "outputId": "0eaad909-963f-4391-e951-ebf3a8d2933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
              "the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 123);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "s3dTtJxkbPEC",
        "outputId": "38742938-0e28-42ee-b29b-04838cd7285a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.affect.get_data.Affectdataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.affect.get_data.Affectdataset</b><br/>def __init__(data: Dict, flatten_time_series: bool, aligned: bool=True, task: str=None, max_pad=False, max_pad_num=50, data_type=&#x27;mosi&#x27;, z_norm=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/MultiBench/datasets/affect/get_data.py</a>Implements Affect data as a torch dataset.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 157);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(traindata.dataset.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h-XcwuFS36Z",
        "outputId": "9aecd7f2-47e5-4c9b-afde-4a7d3a0bfbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpEe92bTTAXL",
        "outputId": "945963f0-b9eb-48f6-ecf9-0d16ce0e8a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vision', 'audio', 'text', 'labels', 'id'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['vision'].shape, traindata.dataset.dataset['audio'].shape, traindata.dataset.dataset['text'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cMNJvLcTKCx",
        "outputId": "2b3b420b-c44d-4d17-a210-2f85853becda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1283, 50, 35), (1283, 50, 74), (1283, 50, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.unimodal import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# mosi_data.pkl, mosei_senti_data.pkl\n",
        "# mosi_raw.pkl, mosei_raw.pkl, sarcasm.pkl, humor.pkl\n",
        "# traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "modality_num = 2\n",
        "\n",
        "# mosi/mosei\n",
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True)\n",
        "head = MLP(600, 512, 1)\n",
        "\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder_modality2.pt', save_head='head_modality2.pt', modalnum=modality_num)\n",
        "\n"
      ],
      "metadata": {
        "id": "mFgMy1hNWQ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing when modality set to :2\")\n",
        "encoder = torch.load('encoder.pt')\n",
        "head = torch.load('head.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=modality_num, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbKzAS-eYT_D",
        "outputId": "52c94d1f-8e9c-4825-b5e7-b3c5468bcdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:\n",
            "loss: tensor(1.4386)\n",
            "acc: 0.4329268292682927, 0.4139941690962099\n",
            "Inference Time: 2.0616798400878906\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "# sys.path.append(os.getcwd())\n",
        "# sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
      ],
      "metadata": {
        "id": "gbZwqi6RlMIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOBkdovUlI8O",
        "outputId": "ef4494cb-ec52-488e-b6a7-34ca19f934c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unimodals.common_models import GRU, MLP, Sequential, Identity  # noqa\n",
        "from training_structures.unimodal import train, test  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# mosi_data.pkl, mosei_senti_data.pkl\n",
        "# mosi_raw.pkl, mosei_raw.pkl, sarcasm.pkl, humor.pkl\n",
        "# traindata, validdata, testdata = get_dataloader('/home/pliang/multibench/affect/pack/mosi/mosi_raw.pkl', robust_test=False)\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)\n",
        "\n",
        "modality_num = 2\n",
        "\n",
        "# mosi/mosei\n",
        "\n",
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder.pt', save_head='head.pt', modalnum=modality_num)\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder.pt').cuda()\n",
        "head = torch.load('head.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=modality_num, no_robust=True)"
      ],
      "metadata": {
        "id": "3as_cV3zi35T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f9f74c-e5d7-4ca6-bd1c-371e75ad94ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.3827, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3888, device='cuda:0')\n",
            "Epoch 2 train loss: tensor(1.3195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3815, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(1.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3866, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 5 train loss: tensor(1.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3844, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.3855, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.3864, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3904, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3987, device='cuda:0')\n",
            "Epoch 10 train loss: tensor(1.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.3718, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 11 train loss: tensor(1.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3709, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 12 train loss: tensor(1.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3864, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3720, device='cuda:0')\n",
            "Epoch 14 train loss: tensor(1.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3481, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 15 train loss: tensor(1.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.2758, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 16 train loss: tensor(1.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.1519, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 17 train loss: tensor(0.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.1506, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 18 train loss: tensor(0.8699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.0353, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 19 train loss: tensor(0.7410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(0.9866, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 20 train loss: tensor(0.6337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.0632, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(0.5588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(0.9913, device='cuda:0')\n",
            "Epoch 22 train loss: tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(0.9625, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 23 train loss: tensor(0.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(0.9755, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(0.9713, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(0.9631, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(0.9677, device='cuda:0')\n",
            "Epoch 28 train loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(0.9739, device='cuda:0')\n",
            "Epoch 29 train loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(0.9873, device='cuda:0')\n",
            "Epoch 30 train loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(0.9852, device='cuda:0')\n",
            "Epoch 31 train loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(0.9913, device='cuda:0')\n",
            "Epoch 32 train loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(0.9792, device='cuda:0')\n",
            "Epoch 33 train loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(0.9817, device='cuda:0')\n",
            "Epoch 34 train loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(0.9847, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(0.9952, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(0.9690, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.0064, device='cuda:0')\n",
            "Epoch 38 train loss: tensor(0.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(0.9711, device='cuda:0')\n",
            "Epoch 39 train loss: tensor(0.1866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(0.9834, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(0.9941, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(0.9782, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(0.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(0.9856, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(0.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.0084, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(0.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.0058, device='cuda:0')\n",
            "Epoch 45 train loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.0013, device='cuda:0')\n",
            "Epoch 46 train loss: tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.0128, device='cuda:0')\n",
            "Epoch 47 train loss: tensor(0.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.0232, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(0.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.0155, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(0.9797, device='cuda:0')\n",
            "Epoch 50 train loss: tensor(0.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.0142, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(0.9839, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.0007, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(0.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.0043, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(0.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.0028, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(0.9846, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(0.9932, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(0.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(0.9866, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(0.9990, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(0.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(0.9935, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.0195, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.0095, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(0.9790, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(0.9867, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.0241, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(0.9950, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(0.0932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.0212, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(0.9891, device='cuda:0')\n",
            "Epoch 70 train loss: tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(0.9983, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.0055, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(0.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.0181, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(0.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.0050, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(0.9997, device='cuda:0')\n",
            "Epoch 75 train loss: tensor(0.0839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(0.9981, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(0.9973, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(0.9891, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.0062, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(0.9851, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(0.0784, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.0078, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(0.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.0167, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(1.0198, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(0.9977, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.0077, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(0.0706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(1.0295, device='cuda:0')\n",
            "Epoch 87 train loss: tensor(0.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.0151, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(0.0644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.0117, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(0.9955, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.0119, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(1.0037, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.0022, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(1.0087, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(0.0772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.0204, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(0.9948, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(0.0765, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.0033, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(0.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.0182, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(1.0206, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Epoch 101 train loss: tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(1.0094, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(0.0632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(0.9940, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(0.0613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(0.9792, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(1.0040, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(1.0072, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(0.0704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(1.0003, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(0.0617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(1.0090, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(0.0609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(0.9952, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.0032, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(1.0083, device='cuda:0')\n",
            "Epoch 113 train loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.0168, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(1.0319, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(0.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.0387, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(1.0047, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(0.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(1.0119, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(0.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.0111, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(0.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(1.0027, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.0110, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(0.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.0081, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(1.0232, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(0.9933, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(0.9881, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(0.9950, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.0109, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(0.0549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(1.0018, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(1.0072, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(0.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(1.0352, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(0.9937, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(0.9839, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.0604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(1.0054, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(0.9991, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(1.0132, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.0522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(0.9940, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(1.0073, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(1.0078, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(1.0126, device='cuda:0')\n",
            "Epoch 140 train loss: tensor(0.0520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(0.9969, device='cuda:0')\n",
            "Epoch 142 train loss: tensor(0.0566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(0.9988, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(1.0057, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(0.9995, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(1.0063, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(1.0131, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(1.0126, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(1.0240, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.0519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(1.0253, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(1.0170, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(1.0165, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(1.0162, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(1.0000, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(1.0124, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(1.0089, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(1.0097, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(1.0291, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(0.9987, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.0812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(1.0318, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.0195, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(1.0454, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(1.0231, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(1.0452, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(1.0384, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.0733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(1.0321, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.0888, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(1.0655, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(1.0166, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(1.0690, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(1.0348, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(1.0432, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(1.0662, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(1.0722, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(1.0625, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(1.0573, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.0603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(1.0612, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(1.0565, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(1.0665, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(1.0607, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(1.0526, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(1.0651, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(1.0563, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(1.0651, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(1.0417, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(1.0447, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.0447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(1.0511, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(1.0486, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(1.0649, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.0595, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.0539, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(1.0684, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.0675, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(1.0597, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(1.0576, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(1.0640, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.0390, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(1.0574, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.0670, device='cuda:0')\n",
            "Training Time: 198.96296048164368\n",
            "Training Peak Mem: 1466.515625\n",
            "Training Params: 1931825\n",
            "Testing:\n",
            "loss: tensor(1.0727, device='cuda:0')\n",
            "acc: 0.7332317073170732, 0.7274052478134111\n",
            "Inference Time: 0.6458330154418945\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhK5iY5vlbXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TvULxoB2u4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "1. Only vision\n",
        "2. Only audio\n",
        "3. Only text\n",
        "4. All three modalities"
      ],
      "metadata": {
        "id": "IK6d1pXlu5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(35, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder0.pt', save_head='head0.pt', modalnum= 0)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder0.pt').cuda()\n",
        "head = torch.load('head0.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=0, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi4mQzhrlemr",
        "outputId": "ff59cb37-8695-4fb3-bf13-2e2b10ec8deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing:\n",
            "loss: tensor(1.6484, device='cuda:0')\n",
            "acc: 0.5350609756097561, 0.5291545189504373\n",
            "Inference Time: 0.41711854934692383\n",
            "Inference Params: 1454825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(74, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder1.pt', save_head='head1.pt', modalnum= 1)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder1.pt').cuda()\n",
        "head = torch.load('head1.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=1, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO_VCtLcnjvw",
        "outputId": "706a872e-caef-4e1b-cd0c-806ce9cd1c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.3793, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 2 train loss: tensor(1.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3863, device='cuda:0')\n",
            "Epoch 3 train loss: tensor(1.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3865, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3818, device='cuda:0')\n",
            "Epoch 5 train loss: tensor(1.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3865, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.4417, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.4052, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3966, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3740, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 10 train loss: tensor(1.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.3874, device='cuda:0')\n",
            "Epoch 11 train loss: tensor(1.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3916, device='cuda:0')\n",
            "Epoch 12 train loss: tensor(1.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3824, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3701, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 14 train loss: tensor(1.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3875, device='cuda:0')\n",
            "Epoch 15 train loss: tensor(1.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.3755, device='cuda:0')\n",
            "Epoch 16 train loss: tensor(1.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.3890, device='cuda:0')\n",
            "Epoch 17 train loss: tensor(1.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.3841, device='cuda:0')\n",
            "Epoch 18 train loss: tensor(1.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.3828, device='cuda:0')\n",
            "Epoch 19 train loss: tensor(1.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(1.4542, device='cuda:0')\n",
            "Epoch 20 train loss: tensor(1.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.3877, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(1.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(1.4081, device='cuda:0')\n",
            "Epoch 22 train loss: tensor(1.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(1.4202, device='cuda:0')\n",
            "Epoch 23 train loss: tensor(1.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(1.4072, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(1.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(1.3822, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(1.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(1.4010, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(1.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(1.3829, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(1.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(1.4068, device='cuda:0')\n",
            "Epoch 28 train loss: tensor(1.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(1.4199, device='cuda:0')\n",
            "Epoch 29 train loss: tensor(1.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(1.3871, device='cuda:0')\n",
            "Epoch 30 train loss: tensor(1.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(1.4357, device='cuda:0')\n",
            "Epoch 31 train loss: tensor(1.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(1.3921, device='cuda:0')\n",
            "Epoch 32 train loss: tensor(1.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(1.3992, device='cuda:0')\n",
            "Epoch 33 train loss: tensor(1.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(1.4165, device='cuda:0')\n",
            "Epoch 34 train loss: tensor(1.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(1.4696, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(1.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(1.3956, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(1.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(1.3953, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(1.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.4864, device='cuda:0')\n",
            "Epoch 38 train loss: tensor(1.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(1.4462, device='cuda:0')\n",
            "Epoch 39 train loss: tensor(1.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(1.4316, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(1.4138, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(1.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(1.4161, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(1.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(1.4241, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(1.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.4946, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(1.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.4028, device='cuda:0')\n",
            "Epoch 45 train loss: tensor(1.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.4523, device='cuda:0')\n",
            "Epoch 46 train loss: tensor(1.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.4264, device='cuda:0')\n",
            "Epoch 47 train loss: tensor(1.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.4578, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(1.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.4466, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(1.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(1.4777, device='cuda:0')\n",
            "Epoch 50 train loss: tensor(1.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.4631, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(1.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(1.4112, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(1.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.4600, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(1.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.4647, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(1.2442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.4440, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(1.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.4280, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(1.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.4123, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(1.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(1.4311, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(1.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(1.4155, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(1.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(1.4959, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(1.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(1.4936, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(1.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(1.4530, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(1.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.4957, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(1.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.4572, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(1.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(1.4141, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(1.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(1.4404, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(1.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.5518, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(1.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(1.4802, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(1.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.4660, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(1.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(1.5076, device='cuda:0')\n",
            "Epoch 70 train loss: tensor(1.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(1.5109, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(1.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.4966, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(1.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.5050, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(1.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.4588, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(1.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(1.5056, device='cuda:0')\n",
            "Epoch 75 train loss: tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(1.5251, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(1.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(1.5353, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(1.5405, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.5587, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(1.5285, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.5748, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.5624, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(1.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(1.6180, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(1.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(1.5009, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.5404, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(1.5252, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(1.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(1.5440, device='cuda:0')\n",
            "Epoch 87 train loss: tensor(1.0915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(1.5501, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(1.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.5442, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.6032, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(1.5266, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.5241, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(1.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(1.5448, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(1.0851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.5515, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(1.0677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(1.5919, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(1.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.5279, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(1.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(1.6133, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(1.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.5228, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.5261, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(1.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(1.6016, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(1.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(1.5739, device='cuda:0')\n",
            "Epoch 101 train loss: tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(1.5723, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(1.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(1.5575, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(1.0428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(1.6263, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(1.0367, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(1.6353, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(1.5459, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(1.0647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(1.5716, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(1.0490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(1.5553, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(1.0524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(1.5945, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(1.5371, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(1.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.5925, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(1.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.6071, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(1.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(1.5567, device='cuda:0')\n",
            "Epoch 113 train loss: tensor(1.0294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.6090, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(1.0415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(1.5997, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(1.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.6099, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(1.6183, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(1.5977, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(1.0280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.5929, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(1.0320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(1.5718, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(1.0240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.5837, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(1.0195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.5508, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(1.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(1.5514, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(1.0131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(1.5860, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.9992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(1.5690, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(1.6308, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.4633, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(1.0389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(1.6391, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(1.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(1.6446, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(1.5861, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(1.0057, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(1.5221, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(1.6022, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(1.5981, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(1.0293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(1.5812, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(1.5986, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.9995, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(1.6381, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(1.6076, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.9918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(1.5631, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.9836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(1.5816, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(1.6064, device='cuda:0')\n",
            "Epoch 140 train loss: tensor(0.9728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(1.6147, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.9812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(1.6596, device='cuda:0')\n",
            "Epoch 142 train loss: tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(1.6289, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.9885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(1.6580, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.9851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(1.6524, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.9553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(1.6299, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.9572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(1.6012, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.9469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(1.5835, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(1.5843, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.9392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(1.6880, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.9458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(1.5223, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.9350, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(1.5344, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.9299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(1.6588, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.9402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(1.5589, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.9246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(1.5852, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.9212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(1.6677, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.9269, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(1.5706, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(1.0137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(1.6761, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.9288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(1.7220, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.9497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(1.5944, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.8994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(1.7024, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.9156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.5983, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(1.6772, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.9188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(1.6285, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.8781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(1.5928, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.8898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(1.6825, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.9696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(1.6197, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.6105, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.8750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(1.6543, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.9094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(1.6114, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.8796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(1.6096, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.8670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(1.6848, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.8913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(1.6211, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(1.5565, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.8775, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(1.6689, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.8746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(1.7173, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(1.6582, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.8740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(1.6280, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(1.6177, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.8402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(1.7046, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(1.6469, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.8316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(1.6027, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.8499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(1.6648, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(1.5946, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.8579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(1.6656, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.8661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(1.5291, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(1.6576, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(1.5510, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(1.6814, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(1.6296, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.6818, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.6221, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(1.5730, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.6207, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.8291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(1.6406, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.8103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(1.6451, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.8239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(1.6518, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.8368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.6498, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.8178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(1.6435, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.8200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.6985, device='cuda:0')\n",
            "Training Time: 197.91238403320312\n",
            "Training Peak Mem: 1478.1484375\n",
            "Training Params: 1525025\n",
            "Testing:\n",
            "loss: tensor(1.4827, device='cuda:0')\n",
            "acc: 0.4405487804878049, 0.42128279883381925\n",
            "Inference Time: 0.4024844169616699\n",
            "Inference Params: 1525025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = GRU(300, 600, dropout=True, has_padding=False,\n",
        "              batch_first=True, last_only=True).cuda()\n",
        "head = MLP(600, 512, 1).cuda()\n",
        "\n",
        "train(encoder, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, lr=2e-3,\n",
        "      weight_decay=0.01, criterion=torch.nn.L1Loss(), save_encoder='encoder2.pt', save_head='head2.pt', modalnum= 2)\n",
        "\n",
        "\n",
        "print(\"Testing:\")\n",
        "encoder = torch.load('encoder2.pt').cuda()\n",
        "head = torch.load('head2.pt')\n",
        "test(encoder, head, testdata, 'affect', criterion=torch.nn.L1Loss(),\n",
        "     task=\"posneg-classification\", modalnum=2, no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0eTG-uZnwOC",
        "outputId": "2c72094b-ead4-4ba9-cc2c-13ddf8fa7b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.4751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(1.5246, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.5094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(1.3872, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(1.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(1.3727, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(1.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(1.3896, device='cuda:0')\n",
            "Epoch 4 train loss: tensor(1.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(1.3694, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 5 train loss: tensor(1.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(1.3795, device='cuda:0')\n",
            "Epoch 6 train loss: tensor(1.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(1.3787, device='cuda:0')\n",
            "Epoch 7 train loss: tensor(1.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(1.3914, device='cuda:0')\n",
            "Epoch 8 train loss: tensor(1.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(1.3696, device='cuda:0')\n",
            "Epoch 9 train loss: tensor(1.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(1.3980, device='cuda:0')\n",
            "Epoch 10 train loss: tensor(1.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(1.4308, device='cuda:0')\n",
            "Epoch 11 train loss: tensor(1.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(1.3818, device='cuda:0')\n",
            "Epoch 12 train loss: tensor(1.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(1.3836, device='cuda:0')\n",
            "Epoch 13 train loss: tensor(1.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(1.3779, device='cuda:0')\n",
            "Epoch 14 train loss: tensor(1.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: tensor(1.3703, device='cuda:0')\n",
            "Epoch 15 train loss: tensor(1.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: tensor(1.3738, device='cuda:0')\n",
            "Epoch 16 train loss: tensor(1.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: tensor(1.3774, device='cuda:0')\n",
            "Epoch 17 train loss: tensor(1.3175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: tensor(1.3755, device='cuda:0')\n",
            "Epoch 18 train loss: tensor(1.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: tensor(1.3692, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 19 train loss: tensor(1.3085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: tensor(1.3926, device='cuda:0')\n",
            "Epoch 20 train loss: tensor(1.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: tensor(1.3713, device='cuda:0')\n",
            "Epoch 21 train loss: tensor(1.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: tensor(1.3656, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 22 train loss: tensor(1.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: tensor(1.3931, device='cuda:0')\n",
            "Epoch 23 train loss: tensor(1.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: tensor(1.3874, device='cuda:0')\n",
            "Epoch 24 train loss: tensor(1.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: tensor(1.3742, device='cuda:0')\n",
            "Epoch 25 train loss: tensor(1.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: tensor(1.3798, device='cuda:0')\n",
            "Epoch 26 train loss: tensor(1.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: tensor(1.3674, device='cuda:0')\n",
            "Epoch 27 train loss: tensor(1.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: tensor(1.3184, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 28 train loss: tensor(1.1931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: tensor(1.2869, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 29 train loss: tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: tensor(1.2373, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 30 train loss: tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: tensor(1.1970, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 31 train loss: tensor(1.0321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: tensor(1.1535, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 32 train loss: tensor(0.9948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: tensor(1.1448, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 33 train loss: tensor(0.9318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: tensor(1.1110, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 34 train loss: tensor(0.8788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: tensor(1.1379, device='cuda:0')\n",
            "Epoch 35 train loss: tensor(0.8337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: tensor(1.1848, device='cuda:0')\n",
            "Epoch 36 train loss: tensor(0.8166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: tensor(1.1192, device='cuda:0')\n",
            "Epoch 37 train loss: tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: tensor(1.0662, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 38 train loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: tensor(1.0303, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 39 train loss: tensor(0.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: tensor(1.0403, device='cuda:0')\n",
            "Epoch 40 train loss: tensor(0.6406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: tensor(1.0576, device='cuda:0')\n",
            "Epoch 41 train loss: tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: tensor(1.0455, device='cuda:0')\n",
            "Epoch 42 train loss: tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: tensor(1.0337, device='cuda:0')\n",
            "Epoch 43 train loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: tensor(1.0652, device='cuda:0')\n",
            "Epoch 44 train loss: tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: tensor(1.0279, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 45 train loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: tensor(1.0233, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 46 train loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: tensor(1.0086, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 47 train loss: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: tensor(1.0745, device='cuda:0')\n",
            "Epoch 48 train loss: tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: tensor(1.0465, device='cuda:0')\n",
            "Epoch 49 train loss: tensor(0.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: tensor(1.0022, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 50 train loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: tensor(1.0405, device='cuda:0')\n",
            "Epoch 51 train loss: tensor(0.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: tensor(1.0306, device='cuda:0')\n",
            "Epoch 52 train loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: tensor(1.0131, device='cuda:0')\n",
            "Epoch 53 train loss: tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: tensor(1.0247, device='cuda:0')\n",
            "Epoch 54 train loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: tensor(1.0175, device='cuda:0')\n",
            "Epoch 55 train loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: tensor(1.0065, device='cuda:0')\n",
            "Epoch 56 train loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: tensor(1.0256, device='cuda:0')\n",
            "Epoch 57 train loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: tensor(1.0326, device='cuda:0')\n",
            "Epoch 58 train loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: tensor(1.0157, device='cuda:0')\n",
            "Epoch 59 train loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: tensor(1.0228, device='cuda:0')\n",
            "Epoch 60 train loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: tensor(1.0216, device='cuda:0')\n",
            "Epoch 61 train loss: tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: tensor(1.0366, device='cuda:0')\n",
            "Epoch 62 train loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: tensor(1.0282, device='cuda:0')\n",
            "Epoch 63 train loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: tensor(1.0436, device='cuda:0')\n",
            "Epoch 64 train loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: tensor(1.0323, device='cuda:0')\n",
            "Epoch 65 train loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: tensor(1.0261, device='cuda:0')\n",
            "Epoch 66 train loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: tensor(1.0568, device='cuda:0')\n",
            "Epoch 67 train loss: tensor(0.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: tensor(1.0253, device='cuda:0')\n",
            "Epoch 68 train loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: tensor(1.0345, device='cuda:0')\n",
            "Epoch 69 train loss: tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: tensor(0.9976, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 70 train loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: tensor(1.0287, device='cuda:0')\n",
            "Epoch 71 train loss: tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: tensor(1.0052, device='cuda:0')\n",
            "Epoch 72 train loss: tensor(0.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: tensor(1.0060, device='cuda:0')\n",
            "Epoch 73 train loss: tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: tensor(1.0275, device='cuda:0')\n",
            "Epoch 74 train loss: tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 75 train loss: tensor(0.1799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: tensor(1.0261, device='cuda:0')\n",
            "Epoch 76 train loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: tensor(1.0142, device='cuda:0')\n",
            "Epoch 77 train loss: tensor(0.1710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: tensor(1.0082, device='cuda:0')\n",
            "Epoch 78 train loss: tensor(0.1590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: tensor(1.0257, device='cuda:0')\n",
            "Epoch 79 train loss: tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: tensor(1.0073, device='cuda:0')\n",
            "Epoch 80 train loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: tensor(1.0263, device='cuda:0')\n",
            "Epoch 81 train loss: tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: tensor(1.0021, device='cuda:0')\n",
            "Epoch 82 train loss: tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: tensor(0.9974, device='cuda:0')\n",
            "Epoch 83 train loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: tensor(1.0280, device='cuda:0')\n",
            "Epoch 84 train loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: tensor(1.0019, device='cuda:0')\n",
            "Epoch 85 train loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: tensor(1.0387, device='cuda:0')\n",
            "Epoch 86 train loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: tensor(0.9875, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 87 train loss: tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: tensor(1.0146, device='cuda:0')\n",
            "Epoch 88 train loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: tensor(1.0178, device='cuda:0')\n",
            "Epoch 89 train loss: tensor(0.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: tensor(1.0002, device='cuda:0')\n",
            "Epoch 90 train loss: tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: tensor(0.9903, device='cuda:0')\n",
            "Epoch 91 train loss: tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: tensor(1.0343, device='cuda:0')\n",
            "Epoch 92 train loss: tensor(0.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: tensor(0.9962, device='cuda:0')\n",
            "Epoch 93 train loss: tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: tensor(1.0282, device='cuda:0')\n",
            "Epoch 94 train loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 95 train loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: tensor(1.0015, device='cuda:0')\n",
            "Epoch 96 train loss: tensor(0.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: tensor(1.0040, device='cuda:0')\n",
            "Epoch 97 train loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: tensor(1.0001, device='cuda:0')\n",
            "Epoch 98 train loss: tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: tensor(1.0315, device='cuda:0')\n",
            "Epoch 99 train loss: tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: tensor(0.9968, device='cuda:0')\n",
            "Epoch 100 train loss: tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: tensor(0.9801, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 101 train loss: tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: tensor(0.9996, device='cuda:0')\n",
            "Epoch 102 train loss: tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: tensor(1.0176, device='cuda:0')\n",
            "Epoch 103 train loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: tensor(1.0143, device='cuda:0')\n",
            "Epoch 104 train loss: tensor(0.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: tensor(1.0002, device='cuda:0')\n",
            "Epoch 105 train loss: tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: tensor(0.9959, device='cuda:0')\n",
            "Epoch 106 train loss: tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: tensor(0.9863, device='cuda:0')\n",
            "Epoch 107 train loss: tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 108 train loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: tensor(0.9961, device='cuda:0')\n",
            "Epoch 109 train loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: tensor(0.9987, device='cuda:0')\n",
            "Epoch 110 train loss: tensor(0.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: tensor(1.0149, device='cuda:0')\n",
            "Epoch 111 train loss: tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: tensor(1.0042, device='cuda:0')\n",
            "Epoch 112 train loss: tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: tensor(0.9776, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 113 train loss: tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: tensor(1.0011, device='cuda:0')\n",
            "Epoch 114 train loss: tensor(0.0877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: tensor(0.9902, device='cuda:0')\n",
            "Epoch 115 train loss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: tensor(1.0074, device='cuda:0')\n",
            "Epoch 116 train loss: tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: tensor(0.9882, device='cuda:0')\n",
            "Epoch 117 train loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: tensor(0.9967, device='cuda:0')\n",
            "Epoch 118 train loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: tensor(1.0058, device='cuda:0')\n",
            "Epoch 119 train loss: tensor(0.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: tensor(0.9904, device='cuda:0')\n",
            "Epoch 120 train loss: tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: tensor(1.0168, device='cuda:0')\n",
            "Epoch 121 train loss: tensor(0.1014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 122 train loss: tensor(0.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: tensor(0.9943, device='cuda:0')\n",
            "Epoch 123 train loss: tensor(0.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: tensor(0.9810, device='cuda:0')\n",
            "Epoch 124 train loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: tensor(1.0130, device='cuda:0')\n",
            "Epoch 125 train loss: tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: tensor(1.0015, device='cuda:0')\n",
            "Epoch 126 train loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: tensor(1.0053, device='cuda:0')\n",
            "Epoch 127 train loss: tensor(0.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: tensor(0.9945, device='cuda:0')\n",
            "Epoch 128 train loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: tensor(0.9999, device='cuda:0')\n",
            "Epoch 129 train loss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: tensor(0.9882, device='cuda:0')\n",
            "Epoch 130 train loss: tensor(0.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: tensor(0.9825, device='cuda:0')\n",
            "Epoch 131 train loss: tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: tensor(1.0053, device='cuda:0')\n",
            "Epoch 132 train loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: tensor(0.9878, device='cuda:0')\n",
            "Epoch 133 train loss: tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: tensor(1.0081, device='cuda:0')\n",
            "Epoch 134 train loss: tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: tensor(0.9883, device='cuda:0')\n",
            "Epoch 135 train loss: tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: tensor(1.0100, device='cuda:0')\n",
            "Epoch 136 train loss: tensor(0.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: tensor(0.9901, device='cuda:0')\n",
            "Epoch 137 train loss: tensor(0.0882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: tensor(0.9850, device='cuda:0')\n",
            "Epoch 138 train loss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: tensor(0.9956, device='cuda:0')\n",
            "Epoch 139 train loss: tensor(0.0847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: tensor(0.9764, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 140 train loss: tensor(0.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: tensor(0.9824, device='cuda:0')\n",
            "Epoch 141 train loss: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: tensor(0.9659, device='cuda:0')\n",
            "Saving Best\n",
            "Epoch 142 train loss: tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: tensor(1.0114, device='cuda:0')\n",
            "Epoch 143 train loss: tensor(0.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: tensor(0.9947, device='cuda:0')\n",
            "Epoch 144 train loss: tensor(0.0800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: tensor(0.9917, device='cuda:0')\n",
            "Epoch 145 train loss: tensor(0.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: tensor(0.9852, device='cuda:0')\n",
            "Epoch 146 train loss: tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: tensor(0.9854, device='cuda:0')\n",
            "Epoch 147 train loss: tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: tensor(0.9968, device='cuda:0')\n",
            "Epoch 148 train loss: tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: tensor(0.9973, device='cuda:0')\n",
            "Epoch 149 train loss: tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: tensor(0.9791, device='cuda:0')\n",
            "Epoch 150 train loss: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: tensor(0.9886, device='cuda:0')\n",
            "Epoch 151 train loss: tensor(0.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: tensor(0.9797, device='cuda:0')\n",
            "Epoch 152 train loss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: tensor(0.9847, device='cuda:0')\n",
            "Epoch 153 train loss: tensor(0.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: tensor(0.9989, device='cuda:0')\n",
            "Epoch 154 train loss: tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: tensor(0.9957, device='cuda:0')\n",
            "Epoch 155 train loss: tensor(0.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: tensor(0.9698, device='cuda:0')\n",
            "Epoch 156 train loss: tensor(0.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: tensor(0.9745, device='cuda:0')\n",
            "Epoch 157 train loss: tensor(0.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: tensor(0.9855, device='cuda:0')\n",
            "Epoch 158 train loss: tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: tensor(0.9878, device='cuda:0')\n",
            "Epoch 159 train loss: tensor(0.0738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: tensor(0.9834, device='cuda:0')\n",
            "Epoch 160 train loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: tensor(0.9860, device='cuda:0')\n",
            "Epoch 161 train loss: tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: tensor(1.0039, device='cuda:0')\n",
            "Epoch 162 train loss: tensor(0.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: tensor(0.9965, device='cuda:0')\n",
            "Epoch 163 train loss: tensor(0.0684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: tensor(0.9966, device='cuda:0')\n",
            "Epoch 164 train loss: tensor(0.0703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: tensor(0.9799, device='cuda:0')\n",
            "Epoch 165 train loss: tensor(0.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: tensor(0.9873, device='cuda:0')\n",
            "Epoch 166 train loss: tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 167 train loss: tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: tensor(1.0112, device='cuda:0')\n",
            "Epoch 168 train loss: tensor(0.0701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: tensor(0.9821, device='cuda:0')\n",
            "Epoch 169 train loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: tensor(0.9991, device='cuda:0')\n",
            "Epoch 170 train loss: tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: tensor(0.9877, device='cuda:0')\n",
            "Epoch 171 train loss: tensor(0.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: tensor(0.9887, device='cuda:0')\n",
            "Epoch 172 train loss: tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: tensor(0.9801, device='cuda:0')\n",
            "Epoch 173 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: tensor(0.9919, device='cuda:0')\n",
            "Epoch 174 train loss: tensor(0.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: tensor(0.9906, device='cuda:0')\n",
            "Epoch 175 train loss: tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: tensor(0.9918, device='cuda:0')\n",
            "Epoch 176 train loss: tensor(0.0753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: tensor(0.9962, device='cuda:0')\n",
            "Epoch 177 train loss: tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: tensor(0.9914, device='cuda:0')\n",
            "Epoch 178 train loss: tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: tensor(0.9941, device='cuda:0')\n",
            "Epoch 179 train loss: tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: tensor(0.9836, device='cuda:0')\n",
            "Epoch 180 train loss: tensor(0.0643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: tensor(0.9908, device='cuda:0')\n",
            "Epoch 181 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: tensor(0.9881, device='cuda:0')\n",
            "Epoch 182 train loss: tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: tensor(0.9910, device='cuda:0')\n",
            "Epoch 183 train loss: tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: tensor(0.9993, device='cuda:0')\n",
            "Epoch 184 train loss: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: tensor(0.9890, device='cuda:0')\n",
            "Epoch 185 train loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: tensor(0.9865, device='cuda:0')\n",
            "Epoch 186 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: tensor(0.9924, device='cuda:0')\n",
            "Epoch 187 train loss: tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: tensor(0.9877, device='cuda:0')\n",
            "Epoch 188 train loss: tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: tensor(0.9969, device='cuda:0')\n",
            "Epoch 189 train loss: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: tensor(0.9904, device='cuda:0')\n",
            "Epoch 190 train loss: tensor(0.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: tensor(1.0035, device='cuda:0')\n",
            "Epoch 191 train loss: tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: tensor(1.0218, device='cuda:0')\n",
            "Epoch 192 train loss: tensor(0.0687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: tensor(0.9971, device='cuda:0')\n",
            "Epoch 193 train loss: tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: tensor(1.0135, device='cuda:0')\n",
            "Epoch 194 train loss: tensor(0.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: tensor(0.9889, device='cuda:0')\n",
            "Epoch 195 train loss: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: tensor(0.9965, device='cuda:0')\n",
            "Epoch 196 train loss: tensor(0.0653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: tensor(0.9955, device='cuda:0')\n",
            "Epoch 197 train loss: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: tensor(1.0181, device='cuda:0')\n",
            "Epoch 198 train loss: tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: tensor(0.9912, device='cuda:0')\n",
            "Epoch 199 train loss: tensor(0.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: tensor(1.0017, device='cuda:0')\n",
            "Training Time: 204.93540453910828\n",
            "Training Peak Mem: 1483.83203125\n",
            "Training Params: 1931825\n",
            "Testing:\n",
            "loss: tensor(1.0228, device='cuda:0')\n",
            "acc: 0.7484756097560976, 0.739067055393586\n",
            "Inference Time: 0.4056661128997803\n",
            "Inference Params: 1931825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jus-RyHpQkbf",
        "outputId": "d0062526-5286-49de-8838-cb395cbbf1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/MultiBench'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "# sys.path.append(os.getcwd())\n",
        "# sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "from training_structures.Supervised_Learning import train, test # noqa\n",
        "from fusions.mult import MULTModel # noqa\n",
        "from unimodals.common_models import Identity, MLP # noqa\n",
        "from datasets.affect.get_data import get_dataloader # noqa\n",
        "from fusions.common_fusions import Concat, MultiplicativeInteractions2Modal, MultiplicativeInteractions3Modal # noqa\n",
        "traindata, validdata, test_robust = get_dataloader('/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True)\n",
        "\n",
        "\n",
        "class HParams():\n",
        "        num_heads = 8\n",
        "        layers = 4\n",
        "        attn_dropout = 0.1\n",
        "        attn_dropout_modalities = [0,0,0.1]\n",
        "        relu_dropout = 0.1\n",
        "        res_dropout = 0.1\n",
        "        out_dropout = 0.1\n",
        "        embed_dropout = 0.2\n",
        "        embed_dim = 40\n",
        "        attn_mask = True\n",
        "        output_dim = 1\n",
        "        all_steps = False\n",
        "\n",
        "encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]\n",
        "# encoders = [Identity().cuda(), Identity().cuda()]\n",
        "# encoders = [GRU(35, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda(),\n",
        "#             GRU(74, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda(),\n",
        "#             GRU(300, 600, dropout=True, has_padding=False,\n",
        "#               batch_first=True, last_only=True).cuda()]\n",
        "fusion = MULTModel(3, [47, 74, 300], hyp_params=HParams).cuda()\n",
        "# fusion = MultiplicativeInteractions3Modal(input_dims= [47, 74, 300], output_dim= 1, task= \"affect\").cuda()\n",
        "# fusion = MultiplicativeInteractions3Modal(input_dims= [47, 74, 300], output_dim= 1, output= \"vector\").cuda()\n",
        "# fusion = MULTModel(3, [371, 81, 300], hyp_params=HParams).cuda()\n",
        "head = Identity().cuda()\n",
        "# head = MLP(600, 512, 1).cuda()\n",
        "train(encoders, fusion, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW, early_stop=False, is_packed=False, lr=1e-3, clip_val=1.0, save='mosi_mult_best.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "print(\"Testing:\")\n",
        "model = torch.load('mosi_mult_best.pt').cuda()\n",
        "\n",
        "test(model=model, test_dataloaders_all=test_robust, dataset='mosi', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task='posneg-classification', no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Ao8MlGf5p57k",
        "outputId": "770b5541-526f-437b-e2d4-0e65c88d5453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MultiBench/fusions/common_fusions.py:141: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.W)\n",
            "/content/MultiBench/fusions/common_fusions.py:144: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.U)\n",
            "/content/MultiBench/fusions/common_fusions.py:147: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.V)\n",
            "/content/MultiBench/fusions/common_fusions.py:149: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.b)\n",
            "/content/MultiBench/fusions/common_fusions.py:155: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.W)\n",
            "/content/MultiBench/fusions/common_fusions.py:157: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.U)\n",
            "/content/MultiBench/fusions/common_fusions.py:159: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  nn.init.xavier_normal(self.V)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cb1e5eb8027d>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#               batch_first=True, last_only=True).cuda()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# fusion = MULTModel(2, [74, 300], hyp_params=HParams).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiplicativeInteractions3Modal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m47\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m74\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"affect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;31m# fusion = MultiplicativeInteractions3Modal(input_dims= [47, 74, 300], output_dim= 1, output= \"vector\").cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# fusion = MULTModel(3, [371, 81, 300], hyp_params=HParams).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLTxl0nzqF0X",
        "outputId": "383a11c5-0142-4e22-cf70-b17c8bdba5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vision', 'audio', 'text', 'labels', 'id'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['vision'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Ln4ZkvrZbb",
        "outputId": "40e0d668-17af-47ec-9bee-7e12e22864aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['audio'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wv3hgnlrd0T",
        "outputId": "d2987405-bdb4-4183-9435-8006ead90f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata.dataset.dataset['text'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PTy5OxCrg_O",
        "outputId": "47bdd5a4-d207-4d27-9e11-a00ff7f1f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1283, 50, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMrbbj9mriHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "\n",
        "from private_test_scripts.all_in_one import all_in_one_train  # noqa\n",
        "from training_structures.Supervised_Learning import train, test  # noqa\n",
        "from unimodals.common_models import GRUWithLinear, MLP  # noqa\n",
        "from datasets.affect.get_data import get_dataloader  # noqa\n",
        "from fusions.common_fusions import Concat, TensorFusion  # noqa\n",
        "\n",
        "\n",
        "# mosi_data.pkl, mosei_senti_data.pkl\n",
        "# mosi_raw.pkl, mosei_raw.pkl, sarcasm.pkl, humor.pkl\n",
        "# raw_path: mosi.hdf5, mosei.hdf5, sarcasm_raw_text.pkl, humor_raw_text.pkl\n",
        "traindata, validdata, test_robust = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False)\n",
        "\n",
        "# mosi/mosei\n",
        "encoders = [GRUWithLinear(35, 64, 4, dropout=True, has_padding=True).cuda(),\n",
        "            GRUWithLinear(74, 128, 19, dropout=True, has_padding=True).cuda(),\n",
        "            GRUWithLinear(300, 512, 79, dropout=True, has_padding=True).cuda()]\n",
        "head = MLP(8000, 512, 1).cuda()\n",
        "\n",
        "# humor/sarcasm\n",
        "# encoders=[GRUWithLinear(371,512,4,dropout=True,has_padding=True).cuda(), \\\n",
        "#     GRUWithLinear(81,256,19,dropout=True,has_padding=True).cuda(),\\\n",
        "#     GRUWithLinear(300,600,79,dropout=True,has_padding=True).cuda()]\n",
        "# head=MLP(8000,512,1).cuda()\n",
        "\n",
        "fusion = TensorFusion().cuda()\n",
        "\n",
        "train(encoders, fusion, head, traindata, validdata, 200, task=\"regression\", optimtype=torch.optim.AdamW,\n",
        "      early_stop=False, is_packed=True, lr=1e-3, save='mosi_tf_best.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "print(\"Testing:\")\n",
        "model = torch.load('mosi_tf_best.pt').cuda()\n",
        "\n",
        "test(model=model, test_dataloaders_all=test_robust, dataset='mosi',\n",
        "     is_packed=True, criterion=torch.nn.L1Loss(), task='posneg-classification', no_robust=True)"
      ],
      "metadata": {
        "id": "gRd_fMwh1xTn",
        "outputId": "734ade57-65ac-4838-fbd6-b30bf67f388f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: 1.2453186511993408\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.0084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: 1.1885693073272705\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(0.9224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: 1.1282635927200317\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(0.8060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: 1.0638257265090942\n",
            "Saving Best\n",
            "Epoch 4 train loss: tensor(0.8006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: 1.0648655891418457\n",
            "Epoch 5 train loss: tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: 1.0146338939666748\n",
            "Saving Best\n",
            "Epoch 6 train loss: tensor(0.6695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: 0.9935763478279114\n",
            "Saving Best\n",
            "Epoch 7 train loss: tensor(0.6320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: 0.9779022336006165\n",
            "Saving Best\n",
            "Epoch 8 train loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: 0.9847762584686279\n",
            "Epoch 9 train loss: tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: 0.9921855330467224\n",
            "Epoch 10 train loss: tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: 0.977034866809845\n",
            "Saving Best\n",
            "Epoch 11 train loss: tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: 0.9417516589164734\n",
            "Saving Best\n",
            "Epoch 12 train loss: tensor(0.4758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: 0.9555070400238037\n",
            "Epoch 13 train loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: 0.9926167130470276\n",
            "Epoch 14 train loss: tensor(0.4591, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: 0.9677488803863525\n",
            "Epoch 15 train loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: 0.9855054616928101\n",
            "Epoch 16 train loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: 0.9232276082038879\n",
            "Saving Best\n",
            "Epoch 17 train loss: tensor(0.3895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: 0.9714354872703552\n",
            "Epoch 18 train loss: tensor(0.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: 0.9467477202415466\n",
            "Epoch 19 train loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: 1.003801703453064\n",
            "Epoch 20 train loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: 0.9937064051628113\n",
            "Epoch 21 train loss: tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: 0.9834131002426147\n",
            "Epoch 22 train loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: 0.936948299407959\n",
            "Epoch 23 train loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: 0.9995985627174377\n",
            "Epoch 24 train loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: 0.9498019218444824\n",
            "Epoch 25 train loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: 0.9631280303001404\n",
            "Epoch 26 train loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: 0.9384512305259705\n",
            "Epoch 27 train loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: 0.9527334570884705\n",
            "Epoch 28 train loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: 0.916336715221405\n",
            "Saving Best\n",
            "Epoch 29 train loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: 0.9315338730812073\n",
            "Epoch 30 train loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: 0.9334045648574829\n",
            "Epoch 31 train loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: 0.9308651685714722\n",
            "Epoch 32 train loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: 0.9485785365104675\n",
            "Epoch 33 train loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: 0.9206798076629639\n",
            "Epoch 34 train loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: 0.9344334006309509\n",
            "Epoch 35 train loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: 0.924687385559082\n",
            "Epoch 36 train loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: 0.9319256544113159\n",
            "Epoch 37 train loss: tensor(0.2103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: 0.8995630741119385\n",
            "Saving Best\n",
            "Epoch 38 train loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: 0.9416235685348511\n",
            "Epoch 39 train loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: 0.9157754778862\n",
            "Epoch 40 train loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: 0.9179853796958923\n",
            "Epoch 41 train loss: tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: 0.9262841939926147\n",
            "Epoch 42 train loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: 0.9243417382240295\n",
            "Epoch 43 train loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: 1.0097688436508179\n",
            "Epoch 44 train loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: 0.9171051979064941\n",
            "Epoch 45 train loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: 0.9691587686538696\n",
            "Epoch 46 train loss: tensor(0.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: 0.9319248795509338\n",
            "Epoch 47 train loss: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: 0.9134050607681274\n",
            "Epoch 48 train loss: tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: 0.920009434223175\n",
            "Epoch 49 train loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: 0.9595358967781067\n",
            "Epoch 50 train loss: tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: 0.9321519136428833\n",
            "Epoch 51 train loss: tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: 0.9252654314041138\n",
            "Epoch 52 train loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: 0.9732909798622131\n",
            "Epoch 53 train loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: 0.9177553653717041\n",
            "Epoch 54 train loss: tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: 0.9522600173950195\n",
            "Epoch 55 train loss: tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: 0.9069174528121948\n",
            "Epoch 56 train loss: tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: 0.9428643584251404\n",
            "Epoch 57 train loss: tensor(0.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: 0.9109468460083008\n",
            "Epoch 58 train loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: 0.9772115349769592\n",
            "Epoch 59 train loss: tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: 0.9416882395744324\n",
            "Epoch 60 train loss: tensor(0.1715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: 0.9329060912132263\n",
            "Epoch 61 train loss: tensor(0.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: 0.955829918384552\n",
            "Epoch 62 train loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: 0.9625881314277649\n",
            "Epoch 63 train loss: tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: 0.9611667990684509\n",
            "Epoch 64 train loss: tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: 0.9395128488540649\n",
            "Epoch 65 train loss: tensor(0.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: 0.9661741852760315\n",
            "Epoch 66 train loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: 0.943301796913147\n",
            "Epoch 67 train loss: tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: 0.953173041343689\n",
            "Epoch 68 train loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: 0.9380530118942261\n",
            "Epoch 69 train loss: tensor(0.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: 0.949926495552063\n",
            "Epoch 70 train loss: tensor(0.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: 0.9693068265914917\n",
            "Epoch 71 train loss: tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: 0.960894763469696\n",
            "Epoch 72 train loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: 0.9488204717636108\n",
            "Epoch 73 train loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: 0.9782803654670715\n",
            "Epoch 74 train loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: 0.9463056325912476\n",
            "Epoch 75 train loss: tensor(0.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: 0.9497895240783691\n",
            "Epoch 76 train loss: tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: 0.962932825088501\n",
            "Epoch 77 train loss: tensor(0.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: 0.9455452561378479\n",
            "Epoch 78 train loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: 0.9098901748657227\n",
            "Epoch 79 train loss: tensor(0.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: 0.9353140592575073\n",
            "Epoch 80 train loss: tensor(0.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: 0.9795085787773132\n",
            "Epoch 81 train loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: 0.9398205280303955\n",
            "Epoch 82 train loss: tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: 0.9313311576843262\n",
            "Epoch 83 train loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: 0.9396504163742065\n",
            "Epoch 84 train loss: tensor(0.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: 0.9154417514801025\n",
            "Epoch 85 train loss: tensor(0.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: 0.9321509599685669\n",
            "Epoch 86 train loss: tensor(0.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: 0.9438026547431946\n",
            "Epoch 87 train loss: tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: 0.9439884424209595\n",
            "Epoch 88 train loss: tensor(0.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: 0.9386130571365356\n",
            "Epoch 89 train loss: tensor(0.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: 0.940200686454773\n",
            "Epoch 90 train loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: 0.9526358246803284\n",
            "Epoch 91 train loss: tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: 0.9415110349655151\n",
            "Epoch 92 train loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: 0.9571052193641663\n",
            "Epoch 93 train loss: tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: 0.9493553638458252\n",
            "Epoch 94 train loss: tensor(0.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: 0.9503369331359863\n",
            "Epoch 95 train loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: 0.956343412399292\n",
            "Epoch 96 train loss: tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: 0.9350732564926147\n",
            "Epoch 97 train loss: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: 0.9591777920722961\n",
            "Epoch 98 train loss: tensor(0.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: 0.9339888691902161\n",
            "Epoch 99 train loss: tensor(0.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: 0.9622764587402344\n",
            "Epoch 100 train loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 100 valid loss: 0.9700655937194824\n",
            "Epoch 101 train loss: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 101 valid loss: 0.9531134963035583\n",
            "Epoch 102 train loss: tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 102 valid loss: 0.9562089443206787\n",
            "Epoch 103 train loss: tensor(0.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 103 valid loss: 0.9591934680938721\n",
            "Epoch 104 train loss: tensor(0.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 104 valid loss: 0.9583988785743713\n",
            "Epoch 105 train loss: tensor(0.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 105 valid loss: 0.9492748975753784\n",
            "Epoch 106 train loss: tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 106 valid loss: 0.9840965867042542\n",
            "Epoch 107 train loss: tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 107 valid loss: 0.9409746527671814\n",
            "Epoch 108 train loss: tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 108 valid loss: 0.9507644176483154\n",
            "Epoch 109 train loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 109 valid loss: 0.9717795252799988\n",
            "Epoch 110 train loss: tensor(0.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 110 valid loss: 0.9618623852729797\n",
            "Epoch 111 train loss: tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 111 valid loss: 0.9375133514404297\n",
            "Epoch 112 train loss: tensor(0.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 112 valid loss: 0.9450210332870483\n",
            "Epoch 113 train loss: tensor(0.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 113 valid loss: 0.9560518860816956\n",
            "Epoch 114 train loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 114 valid loss: 0.9478507041931152\n",
            "Epoch 115 train loss: tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 115 valid loss: 0.9632692337036133\n",
            "Epoch 116 train loss: tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 116 valid loss: 0.9697656035423279\n",
            "Epoch 117 train loss: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 117 valid loss: 0.9771817922592163\n",
            "Epoch 118 train loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 118 valid loss: 0.9732635021209717\n",
            "Epoch 119 train loss: tensor(0.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 119 valid loss: 0.9664009809494019\n",
            "Epoch 120 train loss: tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 120 valid loss: 0.9535265564918518\n",
            "Epoch 121 train loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 121 valid loss: 0.9421523213386536\n",
            "Epoch 122 train loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 122 valid loss: 0.953407883644104\n",
            "Epoch 123 train loss: tensor(0.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 123 valid loss: 0.9572499990463257\n",
            "Epoch 124 train loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 124 valid loss: 0.9581422805786133\n",
            "Epoch 125 train loss: tensor(0.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 125 valid loss: 0.9494330286979675\n",
            "Epoch 126 train loss: tensor(0.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 126 valid loss: 0.9453823566436768\n",
            "Epoch 127 train loss: tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 127 valid loss: 0.9801966547966003\n",
            "Epoch 128 train loss: tensor(0.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 128 valid loss: 0.982498824596405\n",
            "Epoch 129 train loss: tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 129 valid loss: 0.9550586938858032\n",
            "Epoch 130 train loss: tensor(0.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 130 valid loss: 0.9617561101913452\n",
            "Epoch 131 train loss: tensor(0.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 131 valid loss: 0.9486656785011292\n",
            "Epoch 132 train loss: tensor(0.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 132 valid loss: 0.9535830020904541\n",
            "Epoch 133 train loss: tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 133 valid loss: 0.9590544104576111\n",
            "Epoch 134 train loss: tensor(0.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 134 valid loss: 0.9584072232246399\n",
            "Epoch 135 train loss: tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 135 valid loss: 0.9545639753341675\n",
            "Epoch 136 train loss: tensor(0.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 136 valid loss: 0.9727633595466614\n",
            "Epoch 137 train loss: tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 137 valid loss: 0.9660375118255615\n",
            "Epoch 138 train loss: tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 138 valid loss: 0.9476792216300964\n",
            "Epoch 139 train loss: tensor(0.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 139 valid loss: 0.9454813003540039\n",
            "Epoch 140 train loss: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 140 valid loss: 0.9502121806144714\n",
            "Epoch 141 train loss: tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 141 valid loss: 0.971795380115509\n",
            "Epoch 142 train loss: tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 142 valid loss: 0.966552197933197\n",
            "Epoch 143 train loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 143 valid loss: 0.972944974899292\n",
            "Epoch 144 train loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 144 valid loss: 0.9787373542785645\n",
            "Epoch 145 train loss: tensor(0.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 145 valid loss: 0.9481537342071533\n",
            "Epoch 146 train loss: tensor(0.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 146 valid loss: 0.9491455554962158\n",
            "Epoch 147 train loss: tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 147 valid loss: 0.9534420967102051\n",
            "Epoch 148 train loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 148 valid loss: 0.961041271686554\n",
            "Epoch 149 train loss: tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 149 valid loss: 0.9609503149986267\n",
            "Epoch 150 train loss: tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 150 valid loss: 0.9547056555747986\n",
            "Epoch 151 train loss: tensor(0.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 151 valid loss: 0.9451074600219727\n",
            "Epoch 152 train loss: tensor(0.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 152 valid loss: 0.9463880658149719\n",
            "Epoch 153 train loss: tensor(0.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 153 valid loss: 0.968752920627594\n",
            "Epoch 154 train loss: tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 154 valid loss: 0.957861065864563\n",
            "Epoch 155 train loss: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 155 valid loss: 0.9592174291610718\n",
            "Epoch 156 train loss: tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 156 valid loss: 0.9590725302696228\n",
            "Epoch 157 train loss: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 157 valid loss: 0.9489127397537231\n",
            "Epoch 158 train loss: tensor(0.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 158 valid loss: 0.9367053508758545\n",
            "Epoch 159 train loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 159 valid loss: 0.9506251215934753\n",
            "Epoch 160 train loss: tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 160 valid loss: 0.9495151042938232\n",
            "Epoch 161 train loss: tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 161 valid loss: 0.9396190047264099\n",
            "Epoch 162 train loss: tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 162 valid loss: 0.9664130210876465\n",
            "Epoch 163 train loss: tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 163 valid loss: 0.9529304504394531\n",
            "Epoch 164 train loss: tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 164 valid loss: 0.9445511102676392\n",
            "Epoch 165 train loss: tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 165 valid loss: 0.9381308555603027\n",
            "Epoch 166 train loss: tensor(0.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 166 valid loss: 0.9635834693908691\n",
            "Epoch 167 train loss: tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 167 valid loss: 0.9463582038879395\n",
            "Epoch 168 train loss: tensor(0.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 168 valid loss: 0.9598832726478577\n",
            "Epoch 169 train loss: tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 169 valid loss: 0.9566394686698914\n",
            "Epoch 170 train loss: tensor(0.0914, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 170 valid loss: 0.979451596736908\n",
            "Epoch 171 train loss: tensor(0.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 171 valid loss: 0.973583459854126\n",
            "Epoch 172 train loss: tensor(0.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 172 valid loss: 0.9546972513198853\n",
            "Epoch 173 train loss: tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 173 valid loss: 0.9358147382736206\n",
            "Epoch 174 train loss: tensor(0.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 174 valid loss: 0.9583152532577515\n",
            "Epoch 175 train loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 175 valid loss: 0.9556856155395508\n",
            "Epoch 176 train loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 176 valid loss: 0.9414969086647034\n",
            "Epoch 177 train loss: tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 177 valid loss: 0.947800874710083\n",
            "Epoch 178 train loss: tensor(0.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 178 valid loss: 0.9539353847503662\n",
            "Epoch 179 train loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 179 valid loss: 0.9645022749900818\n",
            "Epoch 180 train loss: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 180 valid loss: 0.9598473310470581\n",
            "Epoch 181 train loss: tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 181 valid loss: 0.94843590259552\n",
            "Epoch 182 train loss: tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 182 valid loss: 0.9483240246772766\n",
            "Epoch 183 train loss: tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 183 valid loss: 0.9551091194152832\n",
            "Epoch 184 train loss: tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 184 valid loss: 0.9410820603370667\n",
            "Epoch 185 train loss: tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 185 valid loss: 0.9580127596855164\n",
            "Epoch 186 train loss: tensor(0.0895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 186 valid loss: 0.941705048084259\n",
            "Epoch 187 train loss: tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 187 valid loss: 0.948417603969574\n",
            "Epoch 188 train loss: tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 188 valid loss: 0.9417881369590759\n",
            "Epoch 189 train loss: tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 189 valid loss: 0.9545266628265381\n",
            "Epoch 190 train loss: tensor(0.0876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 190 valid loss: 0.9653829336166382\n",
            "Epoch 191 train loss: tensor(0.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 191 valid loss: 0.9193724393844604\n",
            "Epoch 192 train loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 192 valid loss: 0.948015570640564\n",
            "Epoch 193 train loss: tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 193 valid loss: 0.9238999485969543\n",
            "Epoch 194 train loss: tensor(0.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 194 valid loss: 0.93634033203125\n",
            "Epoch 195 train loss: tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 195 valid loss: 0.9440796375274658\n",
            "Epoch 196 train loss: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 196 valid loss: 0.943144679069519\n",
            "Epoch 197 train loss: tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 197 valid loss: 0.9623715877532959\n",
            "Epoch 198 train loss: tensor(0.0875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 198 valid loss: 0.962347149848938\n",
            "Epoch 199 train loss: tensor(0.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 199 valid loss: 0.9424811005592346\n",
            "Training Time: 502.01667642593384\n",
            "Training Peak Mem: 2621.32421875\n",
            "Training Params: 5488295\n",
            "Testing:\n",
            "acc: 0.6996951219512195, 0.6953352769679301\n",
            "Inference Time: 0.569716215133667\n",
            "Inference Params: 5488295\n"
          ]
        }
      ]
    }
  ]
}